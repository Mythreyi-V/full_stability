{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f21d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, roc_auc_score, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import sklearn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from acv_explainers import ACXplainer\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, rand, early_stop\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from DatasetManager import DatasetManager\n",
    "import BucketFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eea3d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to project folder\n",
    "# please change to your own\n",
    "PATH = os.getcwd()\n",
    "\n",
    "dataset = \"production\"\n",
    "bucket_method = \"prefix\"\n",
    "encoding = \"agg\"\n",
    "cls_method = \"logit\"\n",
    "\n",
    "method_name = bucket_method+\"_\"+encoding\n",
    "\n",
    "random_state = 22\n",
    "exp_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9723cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mythreyi/full_stability/production/logit/prefix_agg\n",
      "/home/mythreyi/full_stability/production/datasets\n"
     ]
    }
   ],
   "source": [
    "method_folder = os.path.join(PATH, dataset, cls_method, method_name)\n",
    "dataset_folder = os.path.join(PATH, dataset, \"datasets\")\n",
    "\n",
    "print(method_folder)\n",
    "print(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cce21beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix\n"
     ]
    }
   ],
   "source": [
    "dataset_ref_to_datasets = {\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"],\n",
    "    \"sepsis_cases\": [\"sepsis_cases_1\"],\n",
    "    \"production\" : [\"production\"]\n",
    "}\n",
    "\n",
    "datasets = [dataset] if dataset not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset]\n",
    "\n",
    "num_buckets = len([name for name in os.listdir(os.path.join(PATH,'%s/%s/%s/pipelines'% (dataset, cls_method, method_name)))])\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "    \n",
    "    min_prefix_length = 1\n",
    "    max_prefix_length = num_buckets\n",
    "\n",
    "    dt_train_prefixes = pd.read_csv(os.path.join(dataset_folder, \"train_prefixes.csv\"))\n",
    "    dt_train_prefixes = dataset_manager.generate_prefix_data(dt_train_prefixes, min_prefix_length, max_prefix_length)\n",
    "\n",
    "    dt_val_prefixes = pd.read_csv(os.path.join(dataset_folder, \"val_prefixes.csv\"))\n",
    "    dt_val_prefixes = dataset_manager.generate_prefix_data(dt_val_prefixes, min_prefix_length, max_prefix_length)\n",
    "    \n",
    "    dt_test_prefixes = pd.read_csv(os.path.join(dataset_folder, \"test_prefixes.csv\"))\n",
    "    dt_test_prefixes = dataset_manager.generate_prefix_data(dt_test_prefixes, min_prefix_length, max_prefix_length)\n",
    "    \n",
    "    if bucket_method == \"state\":\n",
    "        bucket_encoding = \"last\"\n",
    "    else:\n",
    "        bucket_encoding = \"agg\"\n",
    "    \n",
    "    bucketer_args = {'encoding_method':bucket_encoding,\n",
    "                     'case_id_col':dataset_manager.case_id_col, \n",
    "                     'cat_cols':[dataset_manager.activity_col], \n",
    "                     'num_cols':[], \n",
    "                     'random_state':random_state}\n",
    "    bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n",
    "\n",
    "    bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n",
    "    bucket_assignments_val = bucketer.predict(dt_val_prefixes)\n",
    "    bucket_assignments_test = bucketer.predict(dt_test_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b461e8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe22eac22f545f0a189039cff471caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 1\n",
      "Training Score: 0.9901960784313726\n",
      "Testing Score: 0.7272727272727272\n",
      "Bucket 2\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.847457627118644\n",
      "Bucket 3\n",
      "Training Score: 0.9278350515463918\n",
      "Testing Score: 0.8\n",
      "Bucket 4\n",
      "Training Score: 0.8736842105263157\n",
      "Testing Score: 0.8\n",
      "Bucket 5\n",
      "Training Score: 0.974025974025974\n",
      "Testing Score: 0.875\n",
      "Bucket 6\n",
      "Training Score: 0.9848484848484849\n",
      "Testing Score: 0.7407407407407408\n",
      "Bucket 7\n",
      "Training Score: 0.8925619834710743\n",
      "Testing Score: 0.8148148148148148\n",
      "Bucket 8\n",
      "Training Score: 0.9107142857142858\n",
      "Testing Score: 0.7826086956521738\n",
      "Bucket 9\n",
      "Training Score: 0.9357798165137615\n",
      "Testing Score: 0.9473684210526316\n",
      "Bucket 10\n",
      "Training Score: 0.9166666666666666\n",
      "Testing Score: 0.7692307692307692\n",
      "Bucket 11\n",
      "Training Score: 0.9887640449438202\n",
      "Testing Score: 0.8333333333333333\n",
      "Bucket 12\n",
      "Training Score: 0.9302325581395349\n",
      "Testing Score: 0.888888888888889\n",
      "Bucket 13\n",
      "Training Score: 0.9873417721518987\n",
      "Testing Score: 0.8000000000000002\n",
      "Bucket 14\n",
      "Training Score: 0.927536231884058\n",
      "Testing Score: 1.0\n",
      "Bucket 15\n",
      "Training Score: 0.967741935483871\n",
      "Testing Score: 0.5\n",
      "Bucket 16\n",
      "Training Score: 0.9433962264150945\n",
      "Testing Score: 0.0\n",
      "Bucket 17\n",
      "Training Score: 0.9523809523809523\n",
      "Testing Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "for bucket in tqdm_notebook(range(num_buckets)):\n",
    "    bucketID = bucket+1\n",
    "    print ('Bucket', bucketID)\n",
    "\n",
    "    #import everything needed to sort and predict\n",
    "    pipeline_path = os.path.join(method_folder, \"pipelines/pipeline_bucket_%s.joblib\" % \n",
    "                                 (bucketID))\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    feature_combiner = pipeline['encoder']\n",
    "    if 'scaler' in pipeline.named_steps:\n",
    "        scaler = pipeline['scaler']\n",
    "    else:\n",
    "        scaler = None\n",
    "    cls = pipeline['cls']\n",
    "    \n",
    "#     X_train = pd.read_csv(os.path.join(method_folder, \"train_data\", \"train_data_bucket_%s.csv\" % (bucketID)))\n",
    "#     #test_sample = pd.read_csv(os.path.join(method_folder, \"samples\", \"test_sample_bucket_%s.csv\" % (bucketID)))\n",
    "#     #print(feature_combiner, scaler, cls)\n",
    "    \n",
    "#     if scaler!=None:\n",
    "#         X_train = scaler.transform(train_data)\n",
    "\n",
    "    relevant_train_cases_bucket = dataset_manager.get_indexes(dt_train_prefixes)[bucket_assignments_train == bucketID]\n",
    "    dt_train_bucket = dataset_manager.get_relevant_data_by_indexes(dt_train_prefixes, relevant_train_cases_bucket)\n",
    "\n",
    "    X_train = feature_combiner.transform(dt_train_bucket)\n",
    "    if scaler!=None:\n",
    "        X_train = scaler.transform(X_train)\n",
    "        \n",
    "    relevant_val_cases_bucket = dataset_manager.get_indexes(dt_val_prefixes)[bucket_assignments_val == bucketID]\n",
    "    dt_val_bucket = dataset_manager.get_relevant_data_by_indexes(dt_val_prefixes, relevant_val_cases_bucket)\n",
    "\n",
    "    X_val = feature_combiner.transform(dt_val_bucket)\n",
    "    if scaler!=None:\n",
    "        X_val = scaler.transform(X_val)\n",
    "    \n",
    "    relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[bucket_assignments_test == bucketID]\n",
    "    dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n",
    "\n",
    "    test_x = feature_combiner.transform(dt_test_bucket)\n",
    "    if scaler!=None:\n",
    "        test_x = scaler.transform(test_x)\n",
    "    \n",
    "    \n",
    "    Y_pred = cls.predict(X_train)\n",
    "    Y_val = cls.predict(X_val)\n",
    "    test_pred = cls.predict(test_x)\n",
    "    \n",
    "    full_train_x = np.vstack((X_train, X_val))\n",
    "    full_train_y = np.hstack((Y_pred, Y_val))\n",
    "    \n",
    "    #Set up hyperparameter optimisation\n",
    "    kf = KFold(n_splits=5, shuffle = True, random_state=random_state)\n",
    "\n",
    "    space = {\"n_estimators\": scope.int(hp.quniform('n_estimators', 1, 50, q=1)),\n",
    "            \"max_depth\": scope.int(hp.quniform('max_depth', 1, 50, q=1)),\n",
    "            \"sample_fraction\": (hp.quniform('sample_fraction', 0.0001, 1, q=0.4))}\n",
    "\n",
    "    trials = Trials()\n",
    "    \n",
    "    def acv_classifier_optimisation(args, random_state = random_state, cv = kf, X = X_train, y = Y_pred,\n",
    "                                   X_val = X_val, Y_val = Y_val):\n",
    "        score = []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            estimator = ACXplainer(classifier = True, n_estimators = args[\"n_estimators\"], \n",
    "                                   max_depth = args['max_depth'], sample_fraction = args[\"sample_fraction\"])\n",
    "            estimator.fit(X_train, y_train)\n",
    "\n",
    "            score.append(f1_score(Y_val, estimator.predict(X_val)))\n",
    "        \n",
    "        score = np.mean(score)\n",
    "\n",
    "        return -score\n",
    "\n",
    "    best = fmin(acv_classifier_optimisation, verbose=0, space = space, algo=rand.suggest, max_evals = 50, trials=trials, \n",
    "                rstate=np.random.default_rng(random_state), early_stop_fn=early_stop.no_progress_loss(3))\n",
    "    explainer = ACXplainer(classifier = True, n_estimators = int(best['n_estimators']), \n",
    "                           max_depth = int(best['max_depth']), sample_fraction = best['sample_fraction'])\n",
    "    explainer.fit(full_train_x, full_train_y)\n",
    "    \n",
    "    print(\"Training Score:\", f1_score(cls.predict(full_train_x), explainer.predict(full_train_x)))\n",
    "    print(\"Testing Score:\", f1_score(cls.predict(test_x), explainer.predict(test_x)))\n",
    "    \n",
    "    joblib.dump(explainer, method_folder+\"/acv_surrogate/acv_explainer_bucket_%s.joblib\"%(bucketID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9be60e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 144)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[bucket_assignments_test == 16]\n",
    "# dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n",
    "\n",
    "# test_x = feature_combiner.transform(dt_test_bucket)\n",
    "# if scaler!=None:\n",
    "#     test_x = scaler.transform(test_x)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d0c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(explainer.predict(test_x), cls.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "298e1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  0],\n",
       "       [ 2, 20]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(explainer.predict(full_train_x), cls.predict(full_train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae6e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = np.hstack((dataset_manager.get_label_numeric(dt_train_bucket), dataset_manager.get_label_numeric(dt_val_bucket)))\n",
    "sklearn.metrics.confusion_matrix(true, cls.predict(full_train_x))\n",
    "f1_score(true, cls.predict(full_train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99564a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.confusion_matrix(dataset_manager.get_label_numeric(dt_test_bucket), cls.predict(test_x))\n",
    "f1_score(dataset_manager.get_label_numeric(dt_test_bucket), cls.predict(test_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
