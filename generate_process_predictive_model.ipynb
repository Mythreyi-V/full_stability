{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TNrzy43BSk0S"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "import sys\n",
    "import os\n",
    "PATH = os.getcwd()\n",
    "sys.path.append(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5sny80CkSAnW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import EncoderFactory\n",
    "from DatasetManager import DatasetManager\n",
    "import BucketFactory\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from sys import argv\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "#import catboost\n",
    "\n",
    "# from tensorflow.keras.backend import print_tensor\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from keras.layers.core import Dense, Activation, Dropout\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.models import Sequential, Model, load_model\n",
    "# from keras.layers import Dense, Embedding, Flatten, Input\n",
    "# from keras.layers import LSTM\n",
    "# from keras.optimizers import Nadam, RMSprop\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#import lime\n",
    "#import lime.lime_tabular\n",
    "#from lime import submodular_pick;\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1QwzD2NlrroW",
    "outputId": "8d8323ec-c7b3-4459-ab3d-62d2cd95159f"
   },
   "outputs": [],
   "source": [
    "def train_with_unbalanced_data(X_train, X_test, feature_combiner, dataset_manager, current_args, scaler = None, iterations = 10):\n",
    "  all_pipelines = []\n",
    "  all_cls = []\n",
    "  all_acc = []\n",
    "\n",
    "  for j in range(iterations):\n",
    "\n",
    "    #X_train_enc = feature_combiner.fit_transform(X_train, y_train)\n",
    "\n",
    "    y_train = dataset_manager.get_label_numeric(X_train)\n",
    "    #print(len(y_train))\n",
    "    case_ids = dataset_manager.get_case_ids(X_train)\n",
    "    #print(case_ids.shape)\n",
    "\n",
    "    #Reduce to balanced dataset\n",
    "    neg_cases = [case_ids[i] for i in range(len(y_train)) if y_train[i] == 0]\n",
    "    pos_cases = [case_ids[i] for i in range(len(y_train)) if y_train[i] == 1]\n",
    "    \n",
    "    if len(neg_cases) > len(pos_cases):\n",
    "      to_keep = random.sample(neg_cases, len(pos_cases))\n",
    "      X_train_resampled = X_train.loc[X_train[dataset_manager.case_id_col].isin(to_keep)]\n",
    "      X_train_resampled = X_train_resampled.append(X_train.loc[X_train[dataset_manager.case_id_col].isin(pos_cases)])\n",
    "    elif len(neg_cases) < len(pos_cases):\n",
    "      to_keep = random.sample(pos_cases, len(neg_cases))\n",
    "      X_train_resampled = X_train.loc[X_train[dataset_manager.case_id_col].isin(to_keep)]\n",
    "      X_train_resampled = X_train_resampled.append(X_train.loc[X_train[dataset_manager.case_id_col].isin(neg_cases)])\n",
    "\n",
    "    y_train_resampled = dataset_manager.get_label_numeric(X_train_resampled)\n",
    "\n",
    "    #Train model\n",
    "    if cls_method == \"xgboost\":\n",
    "        cls = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                              n_estimators=500,\n",
    "                              learning_rate= current_args['learning_rate'],\n",
    "                              subsample=current_args['subsample'],\n",
    "                              max_depth=int(current_args['max_depth']),\n",
    "                              colsample_bytree=current_args['colsample_bytree'],\n",
    "                              min_child_weight=int(current_args['min_child_weight']),\n",
    "                              seed=random_state)\n",
    "\n",
    "    elif cls_method == \"logit\":\n",
    "        cls = LogisticRegression(C=2**current_args['C'],\n",
    "                              random_state=random_state)\n",
    "    elif cls_method == \"nb\":\n",
    "        cls = GaussianNB(var_smoothing=current_args['var_smoothing'])\n",
    "\n",
    "    if cls_method == \"logit\" or cls_method == \"nb\":\n",
    "        pipeline = Pipeline([('encoder', feature_combiner), ('scaler', StandardScaler()), ('cls', cls)])\n",
    "    else:\n",
    "        pipeline = Pipeline([('encoder', feature_combiner), ('cls', cls)])\n",
    "\n",
    "    print(\"fitting pipeline...\")\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    #Test Model\n",
    "    test_all_grouped = dt_test_bucket.groupby(dataset_manager.case_id_col)\n",
    "    y_test = [dataset_manager.get_label_numeric(group) for _,group in test_all_grouped]\n",
    "    \n",
    "    #print(np.unique(y_train_resampled, return_counts=True))\n",
    "    #print(np.unique(y_test, return_counts=True))\n",
    "\n",
    "    preds = pipeline.predict(X_test)\n",
    "    #print(preds)\n",
    "    acc = f1_score(y_test, preds)\n",
    "\n",
    "    #save to list\n",
    "    all_pipelines.append(pipeline)\n",
    "    all_cls.append(cls)\n",
    "    all_acc.append(acc)\n",
    "  \n",
    "  index = all_acc.index(max(all_acc))\n",
    "    \n",
    "  print(\"Accuracy Scores:\", all_acc)\n",
    "  print(\"Highest accuracy:\", max(all_acc))\n",
    "  print(\"Index:\", index)\n",
    "\n",
    "  pipeline = all_pipelines[index]\n",
    "  cls = all_cls[index]\n",
    "\n",
    "  return pipeline, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 11818,
     "status": "ok",
     "timestamp": 1597794859089,
     "user": {
      "displayName": "Mythreyi Velmurugan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh6DP4Hn-qpp593Bc6lrayXXcdQv42KAS3zJ-Ay=s64",
      "userId": "09509504425224260690"
     },
     "user_tz": -600
    },
    "id": "g32E_o5LSAne",
    "outputId": "e9c23b91-ebd4-4db7-d2b2-f015fea397fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepsis_cases_1']\n"
     ]
    }
   ],
   "source": [
    "dataset_ref = \"sepsis_cases\"\n",
    "params_dir = PATH + \"/params/\"\n",
    "results_dir = \"results\"\n",
    "\n",
    "bucket_method = \"prefix\"\n",
    "cls_encoding = \"agg\"\n",
    "cls_method = \"nb\"\n",
    "\n",
    "gap = 1\n",
    "n_iter = 1\n",
    "\n",
    "balanced_data = False\n",
    "\n",
    "if bucket_method == \"state\":\n",
    "    bucket_encoding = \"last\"\n",
    "else:\n",
    "    bucket_encoding = \"agg\"\n",
    "\n",
    "method_name = \"%s_%s\"%(bucket_method, cls_encoding)\n",
    "\n",
    "dataset_ref_to_datasets = {\n",
    "    \"bpic2012\" : [\"bpic2012_accepted\"],\n",
    "    \"sepsis_cases\": [\"sepsis_cases_1\"],\n",
    "    \"production\" : [\"production\"]\n",
    "}\n",
    "\n",
    "encoding_dict = {\n",
    "    \"laststate\": [\"static\", \"last\"],\n",
    "    \"agg\": [\"static\", \"agg\"],\n",
    "    \"index\": [\"static\", \"index\"],\n",
    "    \"combined\": [\"static\", \"last\", \"agg\"],\n",
    "    \"3d\":[]\n",
    "}\n",
    "\n",
    "datasets = [dataset_ref] if dataset_ref not in dataset_ref_to_datasets else dataset_ref_to_datasets[dataset_ref]\n",
    "methods = encoding_dict[cls_encoding]\n",
    "    \n",
    "train_ratio = 0.8\n",
    "random_state = 22\n",
    "max_prefix = 15\n",
    "\n",
    "# create results directory\n",
    "if not os.path.exists(os.path.join(params_dir)):\n",
    "    os.makedirs(os.path.join(params_dir))\n",
    "    \n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MtUTquMcrrod",
    "outputId": "266ff15e-129c-4446-ad7d-2646d709f9de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up data...\n",
      "Creating logs...\n",
      "bucketing prefixes...\n",
      "prefix\n",
      "Bucket 1\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 0.12328467394420659}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.18840579710144928, 0.18309859154929578, 0.2269503546099291, 0.19402985074626866, 0.19117647058823528, 0.05405405405405406, 0.19999999999999998, 0.2097902097902098, 0.2097902097902098, 0.21428571428571427, 0.18978102189781024, 0.2028985507246377, 0.21276595744680848, 0.21739130434782608, 0.1276595744680851, 0.16666666666666666, 0.2097902097902098, 0.19178082191780824, 0.18978102189781024, 0.169811320754717, 0.19999999999999998, 0.19999999999999998, 0.19718309859154928, 0.17777777777777778, 0.1958041958041958, 0.2097902097902098, 0.22556390977443608, 0.20833333333333331, 0.22388059701492538, 0.0425531914893617, 0.2058823529411765, 0.19178082191780824, 0.19402985074626866, 0.17266187050359713, 0.04761904761904762, 0.2112676056338028, 0.19696969696969696, 0.0, 0.2074074074074074, 0.2043795620437956, 0.18055555555555555, 0.18309859154929578, 0.1925925925925926, 0.0975609756097561, 0.17094017094017094, 0.15748031496062992, 0.16417910447761194, 0.14634146341463414, 0.1793103448275862, 0.2097902097902098]\n",
      "Highest accuracy: 0.2269503546099291\n",
      "Index: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.37       139\n",
      "           1       0.13      0.89      0.23        18\n",
      "\n",
      "    accuracy                           0.31       157\n",
      "   macro avg       0.54      0.56      0.30       157\n",
      "weighted avg       0.85      0.31      0.35       157\n",
      "\n",
      "Bucket 2\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 0.3511191734215131}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.18666666666666665, 0.20833333333333331, 0.1688311688311688, 0.19548872180451127, 0.1739130434782609, 0.15503875968992248, 0.1923076923076923, 0.18571428571428572, 0.17687074829931973, 0.17910447761194032, 0.1904761904761905, 0.19480519480519481, 0.18705035971223022, 0.0, 0.17449664429530204, 0.1843971631205674, 0.15873015873015875, 0.183206106870229, 0.176, 0.14814814814814814, 0.1818181818181818, 0.0, 0.14705882352941177, 0.13999999999999999, 0.19718309859154928, 0.17808219178082194, 0.18055555555555555, 0.03389830508474577, 0.1111111111111111, 0.1879194630872483, 0.052631578947368425, 0.16541353383458646, 0.18840579710144928, 0.15503875968992248, 0.16058394160583941, 0.15789473684210525, 0.17808219178082194, 0.18461538461538463, 0.1793103448275862, 0.17054263565891473, 0.16541353383458646, 0.16296296296296298, 0.16296296296296298, 0.18571428571428572, 0.17449664429530204, 0.1843971631205674, 0.15748031496062992, 0.15942028985507245, 0.08695652173913043, 0.17687074829931973]\n",
      "Highest accuracy: 0.20833333333333331\n",
      "Index: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.20      0.33       139\n",
      "           1       0.12      0.83      0.21        18\n",
      "\n",
      "    accuracy                           0.27       157\n",
      "   macro avg       0.51      0.52      0.27       157\n",
      "weighted avg       0.81      0.27      0.32       157\n",
      "\n",
      "Bucket 3\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 1.519911082952933e-09}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.21621621621621623, 0.0, 0.0, 0.0, 0.10526315789473685, 0.0, 0.0606060606060606, 0.0, 0.0, 0.08333333333333333, 0.0, 0.15789473684210525, 0.0, 0.125, 0.0975609756097561, 0.1111111111111111, 0.20689655172413793, 0.0, 0.0, 0.0, 0.11428571428571428, 0.11764705882352941, 0.0, 0.10256410256410256, 0.0, 0.15625, 0.0, 0.08, 0.16666666666666666, 0.0, 0.17647058823529413, 0.07407407407407407, 0.0, 0.0, 0.058823529411764705, 0.0, 0.06666666666666667, 0.07142857142857142, 0.0, 0.12903225806451615, 0.1276595744680851, 0.09302325581395349, 0.13636363636363638, 0.125, 0.05555555555555555, 0.0, 0.11538461538461539, 0.0, 0.07692307692307691, 0.12000000000000002]\n",
      "Highest accuracy: 0.21621621621621623\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.18      0.30       139\n",
      "           1       0.12      0.89      0.22        18\n",
      "\n",
      "    accuracy                           0.26       157\n",
      "   macro avg       0.52      0.53      0.26       157\n",
      "weighted avg       0.83      0.26      0.29       157\n",
      "\n",
      "Bucket 4\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 6.579332246575682e-08}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.19178082191780824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.07407407407407407, 0.06896551724137931, 0.0625, 0.0, 0.07692307692307691, 0.06666666666666667, 0.1864406779661017, 0.0, 0.0, 0.12903225806451615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999999, 0.20833333333333331, 0.0, 0.0, 0.0, 0.047619047619047616, 0.06451612903225808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Highest accuracy: 0.20833333333333331\n",
      "Index: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.20      0.33       139\n",
      "           1       0.12      0.83      0.21        18\n",
      "\n",
      "    accuracy                           0.27       157\n",
      "   macro avg       0.51      0.52      0.27       157\n",
      "weighted avg       0.81      0.27      0.32       157\n",
      "\n",
      "Bucket 5\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 5.3366992312063123e-05}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.22818791946308725, 0.16806722689075632, 0.0, 0.196078431372549, 0.1925925925925926, 0.08888888888888888, 0.0, 0.0, 0.0, 0.05555555555555555, 0.08, 0.0625, 0.0, 0.0, 0.0, 0.06896551724137932, 0.06451612903225808, 0.0, 0.0, 0.0, 0.0, 0.10810810810810811, 0.0, 0.0, 0.0, 0.0, 0.04761904761904762, 0.0, 0.03636363636363636, 0.0, 0.17582417582417584, 0.1372549019607843, 0.18487394957983194, 0.14457831325301207, 0.171875, 0.1568627450980392, 0.0, 0.1515151515151515, 0.0, 0.17054263565891473, 0.19310344827586207, 0.043478260869565216, 0.0, 0.03448275862068966, 0.0, 0.0, 0.0, 0.0, 0.18348623853211007, 0.10256410256410256]\n",
      "Highest accuracy: 0.22818791946308725\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.18      0.30       139\n",
      "           1       0.13      0.94      0.23        18\n",
      "\n",
      "    accuracy                           0.27       157\n",
      "   macro avg       0.55      0.56      0.27       157\n",
      "weighted avg       0.87      0.27      0.29       157\n",
      "\n",
      "Bucket 6\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 3.5111917342151277e-07}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.21768707482993196, 0.058823529411764705, 0.07407407407407407, 0.0, 0.0, 0.07692307692307691, 0.0625, 0.05555555555555555, 0.06451612903225808, 0.0, 0.08695652173913045, 0.0, 0.058823529411764705, 0.06666666666666667, 0.0, 0.0, 0.06666666666666667, 0.058823529411764705, 0.0, 0.0, 0.07142857142857142, 0.08, 0.0, 0.0, 0.13793103448275862, 0.08333333333333333, 0.0, 0.0, 0.10810810810810811, 0.07692307692307691, 0.0, 0.052631578947368425, 0.0, 0.0625, 0.07407407407407407, 0.0, 0.0, 0.05405405405405406, 0.08695652173913045, 0.06896551724137931, 0.06896551724137931, 0.08, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0606060606060606, 0.05714285714285714, 0.0606060606060606, 0.0625]\n",
      "Highest accuracy: 0.21768707482993196\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.19      0.31       139\n",
      "           1       0.12      0.89      0.22        18\n",
      "\n",
      "    accuracy                           0.27       157\n",
      "   macro avg       0.53      0.54      0.26       157\n",
      "weighted avg       0.84      0.27      0.30       157\n",
      "\n",
      "Bucket 7\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 8.111308307896873e-06}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.2269503546099291, 0.043478260869565216, 0.14285714285714285, 0.125, 0.1212121212121212, 0.13333333333333333, 0.10810810810810811, 0.1212121212121212, 0.15384615384615383, 0.17777777777777776, 0.058823529411764705, 0.11428571428571428, 0.15384615384615383, 0.049999999999999996, 0.11428571428571428, 0.07142857142857142, 0.12903225806451615, 0.058823529411764705, 0.14814814814814814, 0.10256410256410256, 0.06451612903225808, 0.14285714285714285, 0.1212121212121212, 0.2105263157894737, 0.14285714285714285, 0.07407407407407407, 0.14285714285714285, 0.11428571428571428, 0.05714285714285714, 0.049999999999999996, 0.125, 0.125, 0.058823529411764705, 0.14814814814814814, 0.10256410256410256, 0.14814814814814814, 0.14285714285714285, 0.13333333333333333, 0.14814814814814814, 0.20689655172413793, 0.12903225806451615, 0.1212121212121212, 0.125, 0.13333333333333333, 0.10526315789473685, 0.14814814814814814, 0.046511627906976744, 0.07142857142857142, 0.06666666666666667, 0.06896551724137931]\n",
      "Highest accuracy: 0.2269503546099291\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.23      0.37       139\n",
      "           1       0.13      0.89      0.23        18\n",
      "\n",
      "    accuracy                           0.31       157\n",
      "   macro avg       0.54      0.56      0.30       157\n",
      "weighted avg       0.85      0.31      0.35       157\n",
      "\n",
      "Bucket 8\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 0.0533669923120631}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.21276595744680848, 0.2043795620437956, 0.1473684210526316, 0.1746031746031746, 0.11320754716981132, 0.15730337078651685, 0.17647058823529413, 0.13333333333333333, 0.1728395061728395, 0.20155038759689922, 0.1739130434782609, 0.17699115044247787, 0.15151515151515152, 0.1276595744680851, 0.14634146341463414, 0.1774193548387097, 0.17910447761194032, 0.218978102189781, 0.15, 0.1111111111111111, 0.09230769230769229, 0.13559322033898308, 0.18604651162790697, 0.1553398058252427, 0.1142857142857143, 0.1276595744680851, 0.21374045801526717, 0.125, 0.15053763440860216, 0.15384615384615383, 0.14705882352941177, 0.08888888888888888, 0.2043795620437956, 0.1651376146788991, 0.2043795620437956, 0.13675213675213677, 0.0967741935483871, 0.07407407407407407, 0.1923076923076923, 0.11538461538461539, 0.10526315789473684, 0.16949152542372883, 0.20408163265306123, 0.21487603305785125, 0.18571428571428572, 0.2758620689655173, 0.1746031746031746, 0.0975609756097561, 0.2222222222222222, 0.14814814814814814]\n",
      "Highest accuracy: 0.2758620689655173\n",
      "Index: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.84       139\n",
      "           1       0.20      0.44      0.28        18\n",
      "\n",
      "    accuracy                           0.73       157\n",
      "   macro avg       0.56      0.61      0.56       157\n",
      "weighted avg       0.83      0.73      0.77       157\n",
      "\n",
      "Bucket 9\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 1e-07}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.2105263157894737, 0.06666666666666667, 0.06896551724137931, 0.08, 0.06451612903225808, 0.06451612903225808, 0.07142857142857142, 0.125, 0.07407407407407407, 0.125, 0.08, 0.07692307692307691, 0.07692307692307691, 0.06896551724137931, 0.08, 0.06451612903225808, 0.1212121212121212, 0.049999999999999996, 0.0625, 0.05405405405405406, 0.11764705882352941, 0.125, 0.07142857142857142, 0.11764705882352941, 0.08333333333333333, 0.07407407407407407, 0.0625, 0.0975609756097561, 0.08333333333333333, 0.0625, 0.1111111111111111, 0.0606060606060606, 0.12903225806451615, 0.08333333333333333, 0.06451612903225808, 0.06666666666666667, 0.0606060606060606, 0.06451612903225808, 0.08, 0.06666666666666667, 0.08695652173913045, 0.07692307692307691, 0.13793103448275862, 0.05405405405405406, 0.13793103448275862, 0.0975609756097561, 0.05555555555555555, 0.06896551724137931, 0.07142857142857142, 0.0909090909090909]\n",
      "Highest accuracy: 0.2105263157894737\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       136\n",
      "           1       0.20      0.22      0.21        18\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.55      0.55      0.55       154\n",
      "weighted avg       0.81      0.81      0.81       154\n",
      "\n",
      "Bucket 10\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 2.310129700083158e-05}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.22399999999999998, 0.06451612903225808, 0.12000000000000002, 0.06451612903225808, 0.1212121212121212, 0.08695652173913043, 0.0625, 0.06666666666666667, 0.05405405405405406, 0.14545454545454545, 0.046511627906976744, 0.13333333333333333, 0.11428571428571428, 0.1568627450980392, 0.0909090909090909, 0.052631578947368425, 0.07407407407407407, 0.16216216216216214, 0.08333333333333333, 0.06666666666666667, 0.06451612903225808, 0.1212121212121212, 0.06666666666666667, 0.11428571428571428, 0.058823529411764705, 0.04878048780487805, 0.19607843137254904, 0.14814814814814814, 0.08163265306122448, 0.07692307692307691, 0.1111111111111111, 0.07407407407407407, 0.052631578947368425, 0.15384615384615383, 0.13793103448275862, 0.06451612903225808, 0.11764705882352941, 0.06666666666666667, 0.06451612903225808, 0.07692307692307691, 0.07142857142857142, 0.0625, 0.21276595744680854, 0.07407407407407407, 0.06451612903225808, 0.08333333333333333, 0.15384615384615383, 0.07142857142857142, 0.08, 0.06451612903225808]\n",
      "Highest accuracy: 0.22399999999999998\n",
      "Index: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.31      0.46       134\n",
      "           1       0.13      0.78      0.22        18\n",
      "\n",
      "    accuracy                           0.36       152\n",
      "   macro avg       0.52      0.54      0.34       152\n",
      "weighted avg       0.82      0.36      0.43       152\n",
      "\n",
      "Bucket 11\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 6.579332246575682e-08}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.1925925925925926, 0.06896551724137931, 0.07407407407407407, 0.1818181818181818, 0.163265306122449, 0.06451612903225808, 0.07142857142857144, 0.14705882352941177, 0.1875, 0.058823529411764705, 0.08, 0.07692307692307693, 0.06060606060606061, 0.08, 0.14814814814814814, 0.1875, 0.07407407407407407, 0.06060606060606061, 0.045454545454545456, 0.07692307692307693, 0.08695652173913043, 0.06060606060606061, 0.14084507042253522, 0.06451612903225808, 0.048780487804878044, 0.07692307692307693, 0.08695652173913043, 0.07407407407407407, 0.163265306122449, 0.07692307692307693, 0.06666666666666667, 0.08333333333333333, 0.20512820512820512, 0.07692307692307693, 0.07407407407407407, 0.06896551724137931, 0.16666666666666663, 0.13333333333333333, 0.07692307692307693, 0.09090909090909091, 0.14634146341463414, 0.08333333333333333, 0.08333333333333333, 0.1875, 0.08, 0.06666666666666667, 0.07142857142857144, 0.06451612903225808, 0.15999999999999998, 0.0625]\n",
      "Highest accuracy: 0.20512820512820512\n",
      "Index: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.57      0.70       125\n",
      "           1       0.13      0.50      0.21        16\n",
      "\n",
      "    accuracy                           0.56       141\n",
      "   macro avg       0.51      0.53      0.45       141\n",
      "weighted avg       0.81      0.56      0.64       141\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 12\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 2.310129700083158e-07}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.18181818181818182, 0.1, 0.08695652173913043, 0.0689655172413793, 0.09523809523809523, 0.08333333333333333, 0.09090909090909091, 0.0689655172413793, 0.08333333333333333, 0.08333333333333333, 0.07142857142857142, 0.08333333333333333, 0.0625, 0.08695652173913043, 0.09090909090909091, 0.06451612903225808, 0.14634146341463417, 0.09523809523809523, 0.1875, 0.09090909090909091, 0.15, 0.19047619047619047, 0.09090909090909091, 0.08333333333333333, 0.08695652173913043, 0.0625, 0.1, 0.08695652173913043, 0.09523809523809523, 0.08695652173913043, 0.05405405405405405, 0.06666666666666667, 0.0689655172413793, 0.09523809523809523, 0.05555555555555555, 0.08333333333333333, 0.09090909090909091, 0.08, 0.10256410256410256, 0.12903225806451615, 0.06060606060606061, 0.0625, 0.08333333333333333, 0.12903225806451615, 0.07407407407407408, 0.06666666666666667, 0.05555555555555555, 0.1, 0.13043478260869562, 0.06666666666666667]\n",
      "Highest accuracy: 0.19047619047619047\n",
      "Index: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.63      0.74       115\n",
      "           1       0.12      0.43      0.19        14\n",
      "\n",
      "    accuracy                           0.60       129\n",
      "   macro avg       0.51      0.53      0.46       129\n",
      "weighted avg       0.82      0.60      0.68       129\n",
      "\n",
      "Bucket 13\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 0.008111308307896872}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.14285714285714288, 0.21428571428571427, 0.1643835616438356, 0.11428571428571428, 0.08695652173913043, 0.1904761904761905, 0.0909090909090909, 0.13333333333333333, 0.16129032258064518, 0.2181818181818182, 0.11428571428571428, 0.18181818181818182, 0.09523809523809525, 0.18867924528301888, 0.17647058823529413, 0.18867924528301888, 0.1818181818181818, 0.1739130434782609, 0.0851063829787234, 0.19354838709677416, 0.17391304347826086, 0.10000000000000002, 0.16, 0.17910447761194026, 0.10526315789473682, 0.12500000000000003, 0.0930232558139535, 0.175, 0.05263157894736841, 0.18181818181818182, 0.07142857142857142, 0.13953488372093023, 0.1818181818181818, 0.08695652173913043, 0.17142857142857143, 0.13333333333333333, 0.12903225806451613, 0.1846153846153846, 0.0909090909090909, 0.16000000000000003, 0.11428571428571428, 0.08, 0.08, 0.06666666666666667, 0.13333333333333333, 0.15789473684210525, 0.058823529411764705, 0.25, 0.18181818181818182, 0.10810810810810811]\n",
      "Highest accuracy: 0.25\n",
      "Index: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83        99\n",
      "           1       0.17      0.50      0.25        10\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.55      0.62      0.54       109\n",
      "weighted avg       0.87      0.72      0.78       109\n",
      "\n",
      "Bucket 14\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 0.43287612810830584}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.1714285714285714, 0.11594202898550726, 0.11320754716981134, 0.1388888888888889, 0.125, 0.07692307692307691, 0.20689655172413793, 0.19444444444444445, 0.10344827586206896, 0.16666666666666666, 0.19999999999999998, 0.16666666666666669, 0.1282051282051282, 0.12499999999999999, 0.0625, 0.14814814814814814, 0.13333333333333333, 0.13636363636363638, 0.23076923076923078, 0.1639344262295082, 0.15, 0.19444444444444445, 0.3, 0.12903225806451613, 0.1639344262295082, 0.10526315789473685, 0.21052631578947364, 0.1923076923076923, 0.07692307692307691, 0.15384615384615383, 0.13333333333333336, 0.16666666666666669, 0.19607843137254904, 0.052631578947368425, 0.12307692307692307, 0.19999999999999998, 0.16, 0.22222222222222224, 0.1388888888888889, 0.21739130434782608, 0.18867924528301885, 0.18518518518518517, 0.16216216216216217, 0.125, 0.05555555555555556, 0.13333333333333333, 0.14285714285714285, 0.17910447761194032, 0.1875, 0.12698412698412698]\n",
      "Highest accuracy: 0.3\n",
      "Index: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91        82\n",
      "           1       0.25      0.38      0.30         8\n",
      "\n",
      "    accuracy                           0.84        90\n",
      "   macro avg       0.59      0.63      0.61        90\n",
      "weighted avg       0.87      0.84      0.86        90\n",
      "\n",
      "Bucket 15\n",
      "sorting bucket...\n",
      "Setting up parameters...\n",
      "{'var_smoothing': 1.519911082952933e-06}\n",
      "choosing classifier...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "fitting pipeline...\n",
      "Accuracy Scores: [0.13698630136986303, 0.1509433962264151, 0.1904761904761905, 0.1739130434782609, 0.13333333333333333, 0.18181818181818182, 0.14545454545454545, 0.10526315789473685, 0.08333333333333333, 0.09523809523809525, 0.15384615384615385, 0.16666666666666666, 0.11111111111111112, 0.0, 0.22222222222222224, 0.16666666666666666, 0.0, 0.0, 0.15384615384615385, 0.07407407407407407, 0.16666666666666666, 0.15999999999999998, 0.0, 0.14285714285714288, 0.17142857142857143, 0.1, 0.15999999999999998, 0.1702127659574468, 0.07999999999999999, 0.26666666666666666, 0.0, 0.125, 0.13333333333333333, 0.11764705882352941, 0.13333333333333333, 0.16666666666666666, 0.0, 0.1875, 0.125, 0.26666666666666666, 0.2, 0.1904761904761905, 0.09090909090909091, 0.22222222222222224, 0.11111111111111112, 0.07692307692307691, 0.11764705882352941, 0.125, 0.0, 0.0]\n",
      "Highest accuracy: 0.26666666666666666\n",
      "Index: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92        70\n",
      "           1       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.86        78\n",
      "   macro avg       0.60      0.59      0.59        78\n",
      "weighted avg       0.85      0.86      0.85        78\n",
      "\n",
      "All buckets\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.44      0.59      1873\n",
      "           1       0.13      0.68      0.22       236\n",
      "\n",
      "    accuracy                           0.46      2109\n",
      "   macro avg       0.52      0.56      0.41      2109\n",
      "weighted avg       0.83      0.46      0.55      2109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in datasets:\n",
    "    \n",
    "           \n",
    "    # read the data\n",
    "    print(\"setting up data...\")\n",
    "    dataset_manager = DatasetManager(dataset_name)\n",
    "    data = dataset_manager.read_dataset()\n",
    "    cls_encoder_args = {'case_id_col': dataset_manager.case_id_col, \n",
    "                        'static_cat_cols': dataset_manager.static_cat_cols,\n",
    "                        'static_num_cols': dataset_manager.static_num_cols, \n",
    "                        'dynamic_cat_cols': dataset_manager.dynamic_cat_cols,\n",
    "                        'dynamic_num_cols': dataset_manager.dynamic_num_cols, \n",
    "                        'fillna': True}\n",
    "\n",
    "    # determine min and max (truncated) prefix lengths\n",
    "    min_prefix_length = 1\n",
    "    max_prefix_length = max_prefix\n",
    "\n",
    "    dt_train_prefixes = pd.read_csv(os.path.join(PATH, \"%s/datasets/train_prefixes.csv\" % (dataset_ref)))\n",
    "    dt_test_prefixes = pd.read_csv(os.path.join(PATH, \"%s/datasets/test_prefixes.csv\" % (dataset_ref)))\n",
    "    dt_val_prefixes = pd.read_csv(os.path.join(PATH, \"%s/datasets/val_prefixes.csv\" % (dataset_ref)))\n",
    "        \n",
    "    dt_train_prefixes = pd.concat([dt_train_prefixes, dt_val_prefixes])\n",
    "\n",
    "    dt_train_prefixes = dataset_manager.generate_prefix_data(dt_train_prefixes, min_prefix_length, max_prefix_length)\n",
    "    dt_test_prefixes = dataset_manager.generate_prefix_data(dt_test_prefixes, min_prefix_length, max_prefix_length)\n",
    "    \n",
    "    test_y_all = []\n",
    "    preds_all = []\n",
    "    pipelines = []\n",
    "\n",
    "    for ii in range(n_iter):\n",
    "        # create prefix logs\n",
    "        print(\"Creating logs...\")\n",
    "#           dt_train_prefixes = dataset_manager.generate_prefix_data(train, min_prefix_length, max_prefix_length, gap)\n",
    "\n",
    "        # Bucketing prefixes based on control flow\n",
    "        print(\"bucketing prefixes...\")\n",
    "        bucketer_args = {'encoding_method':bucket_encoding,\n",
    "                         'case_id_col':dataset_manager.case_id_col, \n",
    "                         'cat_cols':[dataset_manager.activity_col], \n",
    "                         'num_cols':[], \n",
    "                         'random_state':random_state}\n",
    "        if bucket_method == \"cluster\":\n",
    "            bucketer_args[\"n_clusters\"] = int(args[\"n_clusters\"])\n",
    "        bucketer = BucketFactory.get_bucketer(bucket_method, **bucketer_args)\n",
    "\n",
    "        bucket_assignments_train = bucketer.fit_predict(dt_train_prefixes)\n",
    "        bucket_assignments_test = bucketer.predict(dt_test_prefixes)\n",
    "                \n",
    "        for bucket in set(bucket_assignments_test):\n",
    "            print(\"Bucket\" , bucket )\n",
    "            print(\"sorting bucket...\")\n",
    "            \n",
    "             # load optimal params\n",
    "            print(\"Setting up parameters...\")\n",
    "            optimal_params_filename = os.path.join(params_dir, \"optimal_params_%s_%s_%s_bucket_%s.pickle\" \n",
    "                                                   % (cls_method, dataset_name, method_name, bucket))\n",
    "\n",
    "            if not os.path.isfile(optimal_params_filename) or os.path.getsize(optimal_params_filename) <= 0:\n",
    "                print(\"Parameters not found\")\n",
    "\n",
    "            with open(optimal_params_filename, \"rb\") as fin:\n",
    "                current_args = pickle.load(fin)\n",
    "\n",
    "            print(current_args)\n",
    "            \n",
    "            relevant_train_cases_bucket = dataset_manager.get_indexes(dt_train_prefixes)[bucket_assignments_train == bucket]\n",
    "            relevant_test_cases_bucket = dataset_manager.get_indexes(dt_test_prefixes)[bucket_assignments_test == bucket]\n",
    "            dt_test_bucket = dataset_manager.get_relevant_data_by_indexes(dt_test_prefixes, relevant_test_cases_bucket)\n",
    "\n",
    "            if len(relevant_train_cases_bucket) == 0:\n",
    "                preds = [dataset_manager.get_class_ratio(train)] * len(relevant_test_cases_bucket)\n",
    "                current_online_event_times.extend([0] * len(preds))\n",
    "            else:\n",
    "                dt_train_bucket = dataset_manager.get_relevant_data_by_indexes(dt_train_prefixes, relevant_train_cases_bucket) # one row per event\n",
    "                train_y = dataset_manager.get_label_numeric(dt_train_bucket)\n",
    "\n",
    "                if len(set(train_y)) < 2:\n",
    "                    preds = [train_y[0]] * len(relevant_test_cases_bucket)\n",
    "                else:\n",
    "                    print(\"choosing classifier...\")\n",
    "                    feature_combiner = FeatureUnion([(method, EncoderFactory.get_encoder(method, **cls_encoder_args)) for method in methods])\n",
    "\n",
    "                    if balanced_data==False:\n",
    "                        pipeline, cls = train_with_unbalanced_data(dt_train_bucket, dt_test_bucket, feature_combiner, dataset_manager, current_args, iterations = 50)\n",
    "\n",
    "                    else:\n",
    "                        if cls_method == \"xgboost\":\n",
    "                            cls = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                                                  n_estimators=500,\n",
    "                                                  learning_rate= current_args['learning_rate'],\n",
    "                                                  subsample=current_args['subsample'],\n",
    "                                                  max_depth=int(current_args['max_depth']),\n",
    "                                                  colsample_bytree=current_args['colsample_bytree'],\n",
    "                                                  min_child_weight=int(current_args['min_child_weight']),\n",
    "                                                  seed=random_state)\n",
    "\n",
    "                        elif cls_method == \"logit\":\n",
    "                            cls = LogisticRegression(C=2**current_args['C'],\n",
    "                                                  random_state=random_state)\n",
    "                        elif cls_method == \"nb\":\n",
    "                            cls = GaussianNB(var_smoothing=current_args['var_smoothing'])\n",
    "\n",
    "                        if cls_method == \"logit\" or cls_method == \"nb\":\n",
    "                            pipeline = Pipeline([('encoder', feature_combiner), ('scaler', StandardScaler()), ('cls', cls)])\n",
    "                        else:\n",
    "                            pipeline = Pipeline([('encoder', feature_combiner), ('cls', cls)])\n",
    "\n",
    "                        print(\"fitting pipeline...\")\n",
    "                        pipeline.fit(dt_train_bucket, train_y)\n",
    "                \n",
    "                preds = pipeline.predict(dt_test_bucket)\n",
    "                test_y = dataset_manager.get_label_numeric(dt_test_bucket)\n",
    "                \n",
    "                print(classification_report(test_y, preds))\n",
    "                \n",
    "                test_y_all.extend(test_y)\n",
    "                preds_all.extend(preds)\n",
    "                pipelines.append(pipeline)\n",
    "                \n",
    "                if bucket_method == \"prefix\":\n",
    "                    sample_dfs = []\n",
    "                    pipeline_path = os.path.join(PATH, \"%s/%s/%s/pipelines/pipeline_bucket_%s.joblib\" \n",
    "                                                 % (dataset_ref, cls_method, method_name, bucket))\n",
    "                    joblib.dump(pipeline, pipeline_path)\n",
    "                    \n",
    "                    dt_train_data = pd.DataFrame(feature_combiner.transform(dt_train_bucket), \n",
    "                                                   columns = feature_combiner.get_feature_names())\n",
    "                    \n",
    "                    dt_train_data.to_csv(os.path.join(PATH, \"%s/%s/%s/train_data/train_data_bucket_%s.csv\" \n",
    "                                                 % (dataset_ref, cls_method, method_name, bucket)), index=False)\n",
    "\n",
    "                    \n",
    "                    if len(dataset_manager.get_case_ids(dataset_manager.balance_data(dt_test_bucket))) < 50:\n",
    "                        #print(\"Cases in test data:\", len(dataset_manager.get_case_ids(dt_test_bucket)))\n",
    "                        choose_from = pd.concat([dt_train_bucket, dt_test_bucket])\n",
    "                        \n",
    "                    else:\n",
    "                        #print(len(data_manager.get_case_ids(dt_test_bucket)), \"cases in test data\")\n",
    "                        choose_from = dt_test_bucket\n",
    "                        \n",
    "                    all_y = dataset_manager.get_label_numeric(choose_from)\n",
    "                    case_ids = dataset_manager.get_case_ids(choose_from)\n",
    "\n",
    "                    neg_cases = [case_ids[i] for i in range(len(case_ids)) if all_y[i] == 0]\n",
    "                    pos_cases = [case_ids[i] for i in range(len(case_ids)) if all_y[i] == 1]\n",
    "\n",
    "                    sample_length = min(len(neg_cases), len(pos_cases), 25)\n",
    "                    #print(len(neg_cases),len(pos_cases))\n",
    "\n",
    "                    neg_cases = random.sample(neg_cases, sample_length)\n",
    "                    pos_cases = random.sample(pos_cases, sample_length)\n",
    "\n",
    "                    bal_sample = choose_from.loc[choose_from[dataset_manager.case_id_col].isin(neg_cases)]\n",
    "                    bal_sample = bal_sample.append(choose_from.loc[choose_from[dataset_manager.case_id_col].isin(pos_cases)])\n",
    "                    \n",
    "                    sample_dfs.append(bal_sample)\n",
    "                    bal_sample = pd.concat(sample_dfs)\n",
    "                    \n",
    "                    sample_ids = []\n",
    "                    sample_y = []\n",
    "                    sample_lens = []\n",
    "                    preds = []\n",
    "                    probas = []\n",
    "\n",
    "                    encoded_dfs = []\n",
    "\n",
    "                    for _,group in bal_sample.groupby(dataset_manager.case_id_col):\n",
    "\n",
    "                        sample_ids.append(dataset_manager.get_case_ids(group)[0])\n",
    "                        sample_y.append(dataset_manager.get_label_numeric(group)[0])\n",
    "                        sample_lens.append(dataset_manager.get_prefix_lengths(group).iloc[0])\n",
    "\n",
    "                        pred = int(pipeline.predict(group))\n",
    "                        proba = pipeline.predict_proba(group).reshape(-1)[pred]\n",
    "                        preds.append(pred)\n",
    "                        probas.append(proba)\n",
    "\n",
    "                        encoded_dfs.append(pd.DataFrame(feature_combiner.transform(group), \n",
    "                                                        columns = feature_combiner.get_feature_names()))\n",
    "\n",
    "                    encoded_sample = pd.concat(encoded_dfs)\n",
    "\n",
    "                    rows = np.array([sample_ids, sample_y, sample_lens, preds, probas]).transpose()\n",
    "                    columns = ['Case ID', 'Actual', 'Prefix Length', 'Prediction', 'Prediction Probability']\n",
    "                    results_template = pd.DataFrame(rows, columns = columns)\n",
    "\n",
    "                    encoded_sample.to_csv(os.path.join(PATH,\"%s/%s/%s/samples/test_sample_bucket_%s.csv\") \n",
    "                                          % (dataset_ref, cls_method, method_name, bucket), index=False)\n",
    "                    results_template.to_csv(os.path.join(PATH,\"%s/%s/%s/samples/results_bucket_%s.csv\") \n",
    "                                            % (dataset_ref, cls_method, method_name, bucket), index=False)\n",
    "                \n",
    "        print(\"All buckets\\n\", classification_report(test_y_all, preds_all))\n",
    "        \n",
    "        if bucket_method == \"single\":\n",
    "            sample_dfs = []\n",
    "            pipeline_path = os.path.join(PATH, \"%s/%s/%s/pipelines/pipeline_bucket_%s.joblib\" \n",
    "                                                 % (dataset_ref, cls_method, method_name, bucket))\n",
    "            joblib.dump(pipeline, pipeline_path)\n",
    "            \n",
    "            dt_train_data = pd.DataFrame(feature_combiner.transform(dt_train_bucket), \n",
    "                                                   columns = feature_combiner.get_feature_names())\n",
    "            dt_train_data.to_csv(os.path.join(PATH, \"%s/%s/%s/train_data/train_data_bucket_%s.csv\" \n",
    "                                                 % (dataset_ref, cls_method, method_name, bucket)), index=False)\n",
    "\n",
    "            if len(dataset_manager.get_case_ids(dataset_manager.balance_data(dt_test_bucket))) < 1000:\n",
    "                #print(\"Cases in balanced test data:\", len(dataset_manager.get_case_ids(dataset_manager.balance_data(dt_test_prefixes))))   \n",
    "                choose_from = pd.concat([dt_train_bucket, dt_test_bucket])\n",
    "                \n",
    "            else:\n",
    "                #print(len(data_manager.get_case_ids(dt_test_bucket)), \"cases in balanced test data\")\n",
    "                choose_from = dt_test_bucket\n",
    "            \n",
    "            #sample_dfs = []    \n",
    "            for length in range(max_prefix+1):\n",
    "                choose_from_len = choose_from[choose_from['prefix_nr']==length]\n",
    "                all_y = dataset_manager.get_label_numeric(choose_from_len)\n",
    "                case_ids = dataset_manager.get_case_ids(choose_from_len)\n",
    "\n",
    "                neg_cases = [case_ids[i] for i in range(len(case_ids)) if all_y[i] == 0]\n",
    "                pos_cases = [case_ids[i] for i in range(len(case_ids)) if all_y[i] == 1]\n",
    "\n",
    "                sample_length = min(len(neg_cases), len(pos_cases), 25)\n",
    "                #print(len(neg_cases),len(pos_cases))\n",
    "\n",
    "                neg_cases = random.sample(neg_cases, sample_length)\n",
    "                pos_cases = random.sample(pos_cases, sample_length)\n",
    "\n",
    "                bal_sample = choose_from.loc[choose_from[dataset_manager.case_id_col].isin(neg_cases)]\n",
    "                bal_sample = bal_sample.append(choose_from.loc[choose_from[dataset_manager.case_id_col].isin(pos_cases)])\n",
    "                \n",
    "                sample_dfs.append(bal_sample)\n",
    "                \n",
    "            bal_sample = pd.concat(sample_dfs)\n",
    "                \n",
    "            sample_ids = []\n",
    "            sample_y = []\n",
    "            sample_lens = []\n",
    "            preds = []\n",
    "            probas = []\n",
    "\n",
    "            encoded_dfs = []\n",
    "\n",
    "            for _,group in bal_sample.groupby(dataset_manager.case_id_col):\n",
    "\n",
    "                sample_ids.append(dataset_manager.get_case_ids(group)[0])\n",
    "                sample_y.append(dataset_manager.get_label_numeric(group)[0])\n",
    "                sample_lens.append(dataset_manager.get_prefix_lengths(group).iloc[0])\n",
    "\n",
    "                pred = int(pipeline.predict(group))\n",
    "                proba = pipeline.predict_proba(group).reshape(-1)[pred]\n",
    "                preds.append(pred)\n",
    "                probas.append(proba)\n",
    "\n",
    "                encoded_dfs.append(pd.DataFrame(feature_combiner.transform(group), \n",
    "                                                        columns = feature_combiner.get_feature_names()))\n",
    "            encoded_sample = pd.concat(encoded_dfs)\n",
    "\n",
    "            rows = np.array([sample_ids, sample_y, sample_lens, preds, probas]).transpose()\n",
    "            columns = ['Case ID', 'Actual', 'Prefix Length', 'Prediction', 'Prediction Probability']\n",
    "            results_template = pd.DataFrame(rows, columns = columns)\n",
    "\n",
    "            encoded_sample.to_csv(os.path.join(PATH,\"%s/%s/%s/samples/test_sample_bucket_%s.csv\") \n",
    "                                  % (dataset_ref, cls_method, method_name, bucket), index=False)\n",
    "            results_template.to_csv(os.path.join(PATH,\"%s/%s/%s/samples/results_bucket_%s.csv\") \n",
    "                                    % (dataset_ref, cls_method, method_name, bucket), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15    50\n",
       "Name: Prefix Length, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_template['Prefix Length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VkkmpKvgrro2",
    "outputId": "30f5873d-4f6e-4673-9a39-24137de7f4d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion = confusion_matrix(test_y_all, preds_all)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap='viridis')#, categories = ['Negative', 'Positive'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bpic2012_stability_generate_data_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
